{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Copied Notebook from [this kaggle submission](https://www.kaggle.com/aravindram11/cactus-identification-with-resnet50-99-accuracy/notebook) to see how resnet compares to my highest performance models. Because the performance was similar, I did not move forward with resnet beyond looking at the initial model. ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom skimage import io\nimport matplotlib.pyplot as plt\nimport keras.backend as K\nfrom keras import layers\nfrom keras.layers import Input, Add, Dense, Dropout, MaxPooling2D, Flatten\nfrom keras.models import Model\nfrom keras import optimizers\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import layer_utils\nfrom keras.applications import ResNet50\nfrom keras.applications.resnet50 import preprocess_input\nfrom keras.callbacks import History, ModelCheckpoint, Callback\nfrom sklearn.metrics import roc_auc_score\n\n\nimport os\nprint(os.listdir(\"../input\"))","metadata":{"execution":{"iopub.status.busy":"2021-12-07T22:20:46.246243Z","iopub.execute_input":"2021-12-07T22:20:46.246539Z","iopub.status.idle":"2021-12-07T22:20:49.217364Z","shell.execute_reply.started":"2021-12-07T22:20:46.246487Z","shell.execute_reply":"2021-12-07T22:20:49.216452Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!unzip ../input/train.zip","metadata":{"execution":{"iopub.status.busy":"2021-12-07T22:20:49.219591Z","iopub.execute_input":"2021-12-07T22:20:49.220149Z","iopub.status.idle":"2021-12-07T22:20:52.051891Z","shell.execute_reply.started":"2021-12-07T22:20:49.220096Z","shell.execute_reply":"2021-12-07T22:20:52.050677Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"image = io.imread('train/00a8c7e14298819281fe1a81434d19c4.jpg')\nio.imshow(image)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T22:20:52.053737Z","iopub.execute_input":"2021-12-07T22:20:52.054301Z","iopub.status.idle":"2021-12-07T22:20:52.331137Z","shell.execute_reply.started":"2021-12-07T22:20:52.054244Z","shell.execute_reply":"2021-12-07T22:20:52.330346Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/train.csv')\ntrain_df['has_cactus'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-12-07T22:20:52.332730Z","iopub.execute_input":"2021-12-07T22:20:52.333289Z","iopub.status.idle":"2021-12-07T22:20:52.390768Z","shell.execute_reply.started":"2021-12-07T22:20:52.333238Z","shell.execute_reply":"2021-12-07T22:20:52.390072Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"no_cactus = train_df[train_df['has_cactus'] == 0]\nno_cactus","metadata":{"execution":{"iopub.status.busy":"2021-12-07T22:20:52.393484Z","iopub.execute_input":"2021-12-07T22:20:52.393990Z","iopub.status.idle":"2021-12-07T22:20:52.432988Z","shell.execute_reply.started":"2021-12-07T22:20:52.393942Z","shell.execute_reply":"2021-12-07T22:20:52.432300Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1./255, horizontal_flip=True, vertical_flip=True)\n\nbatch_size = 128\ntrain_df.has_cactus = train_df.has_cactus.astype(str)\n\ntrain_generator = train_datagen.flow_from_dataframe(dataframe = train_df[:14001],directory='train/',x_col='id',\n                                                    y_col='has_cactus',class_mode='binary',batch_size=batch_size,\n                                                    target_size=(32,32))\nval_generator = train_datagen.flow_from_dataframe(dataframe = train_df[14001:],directory='train/',x_col='id',\n                                                    y_col='has_cactus',class_mode='binary',batch_size=batch_size,\n                                                    target_size=(32,32))","metadata":{"execution":{"iopub.status.busy":"2021-12-07T22:20:52.434451Z","iopub.execute_input":"2021-12-07T22:20:52.434945Z","iopub.status.idle":"2021-12-07T22:20:52.643485Z","shell.execute_reply.started":"2021-12-07T22:20:52.434897Z","shell.execute_reply":"2021-12-07T22:20:52.642731Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"num_classes=1\n\ndef get_model():\n    \n    # Get base model: ResNet 50 - don't include the last set of layers dense and FC\n    base_model = ResNet50(weights='imagenet',include_top=False,input_shape=(32, 32, 3))\n    \n    # Freeze the layers in base model\n    for layer in base_model.layers:\n        layer.trainable = True\n        \n    # Get output from base model\n    base_model_output = base_model.output\n    \n    # Add our layers of Dense and FC at the end\n    \n    # FC layer and softmax\n    last_layers = Flatten()(base_model_output)\n    last_layers = Dense(512,activation='relu')(last_layers)\n    last_layers = Dense(num_classes,activation='sigmoid',name='fcnew')(last_layers)\n    \n    model = Model(inputs=base_model.input,outputs=last_layers)\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-07T22:20:52.644798Z","iopub.execute_input":"2021-12-07T22:20:52.645321Z","iopub.status.idle":"2021-12-07T22:20:52.653644Z","shell.execute_reply.started":"2021-12-07T22:20:52.645272Z","shell.execute_reply":"2021-12-07T22:20:52.652771Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"model = get_model()\noptimizer = optimizers.adam(lr=0.0001)\nmodel.compile(loss='binary_crossentropy',optimizer=optimizer, metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-07T22:20:52.654948Z","iopub.execute_input":"2021-12-07T22:20:52.655490Z","iopub.status.idle":"2021-12-07T22:21:08.669724Z","shell.execute_reply.started":"2021-12-07T22:20:52.655438Z","shell.execute_reply":"2021-12-07T22:21:08.669031Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class Loss(Callback):    \n    def on_train_begin(self, logs={}):\n        self.losses = []\n        logs['val_auc'] = 0\n            \n    def on_epoch_begin(self, epoch, logs={}):\n        return\n    \n    def on_epoch_end(self, epoch, logs={}):\n        self.losses.append(logs['loss'])\n        \n        y_p = []\n        y_v = []\n        for i in range(len(val_generator)):\n            x_val, y_val = val_generator[i]\n            y_pred = self.model.predict(x_val)\n            y_p.append(y_pred)\n            y_v.append(y_val)\n        y_p = np.concatenate(y_p)\n        y_v = np.concatenate(y_v)\n        roc_auc = roc_auc_score(y_v, y_p)\n        print ('\\nVal AUC for epoch{}: {}'.format(epoch, roc_auc))\n        logs['val_auc']=roc_auc","metadata":{"execution":{"iopub.status.busy":"2021-12-07T22:21:08.671004Z","iopub.execute_input":"2021-12-07T22:21:08.671312Z","iopub.status.idle":"2021-12-07T22:21:08.688950Z","shell.execute_reply.started":"2021-12-07T22:21:08.671265Z","shell.execute_reply":"2021-12-07T22:21:08.688266Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"epochs = 10\n\nloss = Loss()\ncheckpoint = ModelCheckpoint(\"best_model.hdf5\", monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True, mode='min', period=1)\nhistory = model.fit_generator(train_generator,\n                    steps_per_epoch=train_generator.n//batch_size,\n                   validation_data=val_generator,\n                   validation_steps=val_generator.n//batch_size,\n                   epochs=epochs,\n                   callbacks=[loss,checkpoint]\n    )","metadata":{"execution":{"iopub.status.busy":"2021-12-07T22:21:08.690121Z","iopub.execute_input":"2021-12-07T22:21:08.690603Z","iopub.status.idle":"2021-12-07T22:24:16.857982Z","shell.execute_reply.started":"2021-12-07T22:21:08.690394Z","shell.execute_reply":"2021-12-07T22:24:16.857152Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"\ndef visualize_training_results(history):\n    '''\n    From https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n    \n    Input: keras history object (output from trained model)\n    '''\n    fig, (ax1, ax2) = plt.subplots(2, sharex=True)\n    fig.suptitle('Model Results')\n\n    # summarize history for accuracy\n    ax1.plot(history.history['accuracy'])\n    ax1.plot(history.history['val_accuracy'])\n    ax1.set_ylabel('Accuracy')\n    ax1.legend(['train', 'test'], loc='upper left')\n    # summarize history for loss\n    ax2.plot(history.history['loss'])\n    ax2.plot(history.history['val_loss'])\n    ax2.set_ylabel('Loss')\n    ax2.legend(['train', 'test'], loc='upper left')\n    \n    plt.xlabel('Epoch')\n    plt.show()\n    \ndef plot_performance(hist):\n    \"\"\" Returns 4 plots comparing Training and Validation data. \n    First plot returns training and validation accuracy. \n    Second plot returns training and validation loss. \n    Third plot returns training and validation F1-Scores. \n    Fourth plot returns training and validation recall scores. \n    \n    hist: input history model containing train images, labels, and validation data. t\"\"\"\n    \n    hist_ = hist.history\n    epochs = hist.epoch\n    \n    plt.plot(epochs, hist_['accuracy'], label='Training Accuracy')\n    plt.plot(epochs, hist_['val_accuracy'], label='Validation Accuracy')\n    plt.title('Training and validation accuracy')\n    plt.legend()\n    plt.figure()\n    \n    plt.plot(epochs, hist_['loss'], label='Training loss')\n    plt.plot(epochs, hist_['val_loss'], label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.legend()\n    recall = np.array(hist_['recall'])\n    precision = np.array(hist_['precision'])\n    val_recall = np.array(hist_['val_recall'])\n    val_precision = np.array(hist_['val_precision'])\n    plt.figure()\n    \n    plt.plot(epochs, \n             2*((recall * precision)/(recall + precision)), \n             label='Training f1')\n    plt.plot(epochs, \n             2*((val_recall * val_precision)/(val_recall + val_precision)), \n             label='Validation f1')\n    plt.title('Training and validation F1-Score')\n    plt.legend()\n    plt.figure()\n    \n    plt.plot(epochs, recall, label = \"Training Recall\")\n    plt.plot(epochs, val_recall, label = \"Validation Recall\")\n    plt.title(\"Training and Validation Recall Scores\")\n    plt.legend()\n    plt.figure()\n    \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-07T22:24:16.859374Z","iopub.execute_input":"2021-12-07T22:24:16.859812Z","iopub.status.idle":"2021-12-07T22:24:16.878223Z","shell.execute_reply.started":"2021-12-07T22:24:16.859761Z","shell.execute_reply":"2021-12-07T22:24:16.877557Z"},"trusted":true},"execution_count":11,"outputs":[]}]}